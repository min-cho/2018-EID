# -*- coding: utf-8 -*-
"""
Created on Wed May 16 16:21:57 2018
@author: cho
"""

import keras
import numpy as np
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Activation
from keras.layers import Dense, LSTM, Dropout
import os
from keras.utils.vis_utils import plot_model
import matplotlib.pyplot as plt


timesteps = seq_length = 7
data_dim = 9

chl_max = 107.5
chl_min = 1.9

# data

xy = np.loadtxt('data_1.csv', delimiter=',')  

np.random.seed(777)
np.random.shuffle(xy)

dataX=xy[:,0:63]
dataY=xy[:,63]

# split to train and testing

train_size = int(len(dataY) * 0.6)
val_size=int(len(dataY)*0.2)
nontest_size=train_size+val_size
test_size = len(dataY) - train_size -val_size

trainX, testX = np.array(dataX[0:train_size]), np.array(dataX[nontest_size:len(dataX)])
trainY, testY = np.array(dataY[0:train_size]), np.array(dataY[nontest_size:len(dataY)])
valX=np.array(dataX[train_size:nontest_size])
valY=np.array(dataY[train_size:nontest_size])

##############################################################################

#model1 : 3 dense
model1 = Sequential()
model1.add(Dense(16, input_dim=63, activation='relu'))
model1.add(Dense(4, activation='relu'))
model1.add(Dense(1))
model1.add(Activation("linear"))
model1.compile(loss='mean_squared_error', optimizer='adam')
model1.summary()

##############################################################################

#model2: 5 dense
model2 = Sequential()
model2.add(Dense(32, input_dim=63, activation='relu'))
model2.add(Dense(16, activation='relu'))
model2.add(Dense(16, activation='relu'))
model2.add(Dense(4, activation='relu'))
model2.add(Dense(1))
model2.add(Activation("linear"))
model2.compile(loss='mean_squared_error', optimizer='adam')
model2.summary()

#############################################################################

# Model3 : 2LSTM

### RESHPAE THE DATA to LSTM

trainX=np.reshape(trainX,(train_size,timesteps,data_dim))
trainY=np.reshape(trainY,(train_size,1))
testX=np.reshape(testX,(test_size,timesteps,data_dim))
testY=np.reshape(testY,(test_size,1))
valX=np.reshape(valX,(val_size,timesteps,data_dim))
valY=np.reshape(valY,(val_size,1))

model3 = Sequential()
model3.add(LSTM(16, input_shape=(timesteps,data_dim), return_sequences=True))
#model.add(Dropout(0.2))
model3.add(LSTM(9, return_sequences=False)) #DEEPER
model3.add(Dense(1))
model3.add(Activation("linear"))
model3.compile(loss='mean_squared_error', optimizer='adam')
model3.summary()

################ training ###########################

model = model3

###
# Store model graph in png # (Error occurs on in python interactive shell)
#plot_model(model, to_file=os.path.basename(__file__) + '.png', show_shapes=True)
#print(trainX.shape, trainY.shape)

hist=model.fit(trainX, trainY, epochs=200,validation_data=(valX, valY))

# make predictions
testPredict = model.predict(testX)

# PLOT with inverse values
plt.plot(testY*(chl_max-chl_min)+chl_min)
plt.plot(testPredict*(chl_max-chl_min)+chl_min)
plt.legend(['True', 'Predict'], loc='upper left')
plt.ylabel('Concentration of chl-a (mg/m3)')
plt.xlabel('Days')
plt.show()


# 5. 학습과정 살펴보기
plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.ylim(0.0, 0.03)
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()


# 6. 모델 평가하기 - RMSE
trainScore = model.evaluate(trainX, trainY, verbose=0) ** (.5)
model.reset_states()
print('Train Score: ', trainScore)
valScore = model.evaluate(valX, valY, verbose=0) ** (.5)
model.reset_states()
print('Validataion Score: ', valScore)
testScore = model.evaluate(testX, testY, verbose=0) ** (.5)
model.reset_states()
print('Test Score: ', testScore)


## 레이어 구조 시각화
from IPython.display import SVG
from keras.utils.vis_utils import model_to_dot
SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))
